import os
import json
import requests
import argparse
from datetime import datetime

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
OLLAMA_URL = "http://localhost:11434/api/chat"
MODEL_NAME = "qwen2.5:1.5b"  # <--- –õ–ï–ì–ö–ê–Ø –ú–û–î–ï–õ–¨
BATCH_SIZE = 3               # <--- –ú–ï–ù–¨–®–ï –ù–ê–ì–†–£–ó–ö–ê

BASE_DIR = "/root/sales-ai-agent"
DATA_DIR = os.path.join(BASE_DIR, "data/archive")
PROMPTS_FILE = os.path.join(BASE_DIR, "data/prompts.json")

RUS_NAMES = {
    "Volkov_Ivan": "–ò–≤–∞–Ω –í–æ–ª–∫–æ–≤",
    "Popov_Denis": "–î–µ–Ω–∏—Å –ü–æ–ø–æ–≤",
    "Ahmedshin_Dmitry": "–î–º–∏—Ç—Ä–∏–π –ê—Ö–º–µ–¥—à–∏–Ω",
    "Garyaev_Maxim": "–ú–∞–∫—Å–∏–º –ì–∞—Ä—è–µ–≤",
    "Ivanova_Elena": "–ï–ª–µ–Ω–∞ –ò–≤–∞–Ω–æ–≤–∞"
}

def query_ollama_stream(messages):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å)"""
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "stream": True,  # <--- –í–ö–õ–Æ–ß–ê–ï–ú –°–¢–†–ò–ú
        "options": {
            "temperature": 0.3,
            "num_ctx": 4096 
        }
    }
    
    full_response = ""
    try:
        with requests.post(OLLAMA_URL, json=payload, stream=True, timeout=600) as r:
            if r.status_code != 200:
                print(f"‚ùå –û—à–∏–±–∫–∞ API: {r.status_code}")
                return None
                
            print("   ü§ñ Ollama –¥—É–º–∞–µ—Ç: ", end="", flush=True)
            for line in r.iter_lines():
                if line:
                    body = json.loads(line)
                    if "message" in body and "content" in body["message"]:
                        token = body["message"]["content"]
                        print(token, end="", flush=True)
                        full_response += token
                    if body.get("done", False):
                        break
            print("\n") # –ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞
            return full_response
            
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

def analyze_batch(batch_texts, batch_idx, company_context):
    print(f"\nüîπ –ë–ê–¢–ß #{batch_idx} ({len(batch_texts)} –∑–≤–æ–Ω–∫–æ–≤)...")
    combined_text = "\n\n".join(batch_texts)
    
    system_prompt = "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞–π–¥–∏ –æ—à–∏–±–∫–∏ –∏ —É—Å–ø–µ—Ö–∏ –≤ –¥–∏–∞–ª–æ–≥–∞—Ö."
    user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç: {company_context}
    
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥–∏. –ö—Ä–∞—Ç–∫–æ –≤—ã–ø–∏—à–∏:
1. –ü–õ–Æ–°–´ (—Ñ—Ä–∞–∑—ã).
2. –ú–ò–ù–£–°–´ (–æ—à–∏–±–∫–∏).

–î–ò–ê–õ–û–ì–ò:
{combined_text}
"""
    return query_ollama_stream([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ])

def analyze_with_ollama(week, company, manager):
    rus_name = RUS_NAMES.get(manager, manager)
    print(f"\nüöÄ –¢–ï–°–¢ OLLAMA (LITE): {rus_name} | –ú–æ–¥–µ–ª—å: {MODEL_NAME}")
    
    mgr_dir = os.path.join(DATA_DIR, week, company, manager)
    transcripts_dir = os.path.join(mgr_dir, "transcripts")
    
    if not os.path.exists(transcripts_dir):
        print("‚ùå –ù–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤")
        return

    files = sorted([f for f in os.listdir(transcripts_dir) if f.endswith(".txt")])
    if not files: return

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï
    all_calls = []
    for f in files:
        with open(os.path.join(transcripts_dir, f), "r", encoding="utf-8") as file:
            content = file.read().strip()
            if len(content) > 100:
                all_calls.append(f"=== {f} ===\n{content}")
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_calls)} –∑–≤–æ–Ω–∫–æ–≤.")
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞—á–∫–∏
    batches = [all_calls[i:i + BATCH_SIZE] for i in range(0, len(all_calls), BATCH_SIZE)]
    print(f"üîÑ –í—Å–µ–≥–æ {len(batches)} –ø–∞—á–µ–∫ (–ø–æ {BATCH_SIZE} —à—Ç).")
    
    batch_results = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
    for i, batch in enumerate(batches, 1):
        res = analyze_batch(batch, i, "–ü—Ä–æ–¥–∞–∂–∏")
        if res:
            batch_results.append(res)
        else:
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ –ø–∞—á–∫–∏.")

    # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    print(f"\nüèÅ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–¢–û–ì–û–í–û–ì–û –û–¢–ß–ï–¢–ê...")
    all_findings = "\n\n".join(batch_results)
    
    final_prompt = f"""–°–æ—Å—Ç–∞–≤—å –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä—É {rus_name} –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–º–µ—Ç–æ–∫:

{all_findings}

–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
# –û–¶–ï–ù–ö–ê (0-100)
# –ì–õ–ê–í–ù–´–ô –í–´–í–û–î
# –ü–õ–Æ–°–´
# –ú–ò–ù–£–°–´
# –°–û–í–ï–¢–´
"""
    final_report = query_ollama_stream([
        {"role": "user", "content": final_prompt}
    ])
    
    if final_report:
        report_path = os.path.join(mgr_dir, "report", f"OLLAMA_LITE_{manager}.md")
        os.makedirs(os.path.dirname(report_path), exist_ok=True)
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(final_report)
        print(f"\n‚úÖ –°–û–•–†–ê–ù–ï–ù–û: {report_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--week", required=True)
    parser.add_argument("--company", required=True)
    parser.add_argument("--manager", required=True)
    args = parser.parse_args()
    
    analyze_with_ollama(args.week, args.company, args.manager)
