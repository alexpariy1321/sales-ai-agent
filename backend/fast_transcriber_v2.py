from backend.torch_patch import patched_load
import torch
torch.load = patched_load

import whisperx
from pyannote.audio import Pipeline
import gc
import os
import warnings
from dotenv import load_dotenv

warnings.filterwarnings("ignore", category=UserWarning)
load_dotenv()

class FastTranscriber:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∞–π–±–µ—Ä –¥–ª—è –∑–≤–æ–Ω–∫–æ–≤ (–≤—Å–µ–≥–¥–∞ 2 —Å–ø–∏–∫–µ—Ä–∞)"""
    
    def __init__(self, model_name="tiny", device="cpu"):
        self.device = device
        self.model_name = model_name
        self.hf_token = (
            os.getenv("HF_TOKEN") or 
            os.getenv("HUGGINGFACE_TOKEN") or 
            os.getenv("HFTOKEN")
        )
        
        print(f"üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º WhisperX –º–æ–¥–µ–ª—å '{model_name}'...")
        self.model = whisperx.load_model(
            model_name, 
            device=device, 
            compute_type="int8",
            language="ru"
        )
        
        print("üéØ –ó–∞–≥—Ä—É–∂–∞–µ–º align –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ...")
        self.align_model, self.align_metadata = whisperx.load_align_model(
            language_code="ru", 
            device=device
        )
        
        print("üë• –ó–∞–≥—Ä—É–∂–∞–µ–º diarization –º–æ–¥–µ–ª—å (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ 2 —Å–ø–∏–∫–µ—Ä–∞)...")
        if self.hf_token:
            try:
                self.diarize_model = Pipeline.from_pretrained(
                    "pyannote/speaker-diarization-3.1",
                    use_auth_token=self.hf_token
                )
                self.diarize_model.to(torch.device(device))
                print("   ‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞!")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞: {str(e)[:80]}")
                self.diarize_model = None
        else:
            self.diarize_model = None
            print("   ‚ö†Ô∏è  HF_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        print("‚úÖ –ì–æ—Ç–æ–≤–æ!\n")
    
    def transcribe_with_speakers(self, audio_path: str) -> dict:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π (2 —Å–ø–∏–∫–µ—Ä–∞: –º–µ–Ω–µ–¥–∂–µ—Ä + –∫–ª–∏–µ–Ω—Ç)"""
        try:
            audio = whisperx.load_audio(audio_path)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
            result = self.model.transcribe(audio, batch_size=16)
            
            # Align
            result = whisperx.align(
                result["segments"], 
                self.align_model, 
                self.align_metadata, 
                audio, 
                self.device,
                return_char_alignments=False
            )
            
            # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
            if self.diarize_model:
                try:
                    audio_tensor = torch.from_numpy(audio).unsqueeze(0)
                    waveform = {"waveform": audio_tensor, "sample_rate": 16000}
                    
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ 2 —Å–ø–∏–∫–µ—Ä–∞ (min=2, max=2)
                    diarization = self.diarize_model(
                        waveform,
                        min_speakers=2,
                        max_speakers=2
                    )
                    
                    # –ú–∞–ø–ø–∏–Ω–≥ —Å–ø–∏–∫–µ—Ä–æ–≤: SPEAKER_00 = –º–µ–Ω–µ–¥–∂–µ—Ä, SPEAKER_01 = –∫–ª–∏–µ–Ω—Ç
                    for segment in result["segments"]:
                        segment_start = segment["start"]
                        segment_end = segment["end"]
                        
                        speakers_in_segment = []
                        for turn, _, speaker in diarization.itertracks(yield_label=True):
                            if turn.start < segment_end and turn.end > segment_start:
                                overlap = min(turn.end, segment_end) - max(turn.start, segment_start)
                                speakers_in_segment.append((speaker, overlap))
                        
                        if speakers_in_segment:
                            dominant_speaker = max(speakers_in_segment, key=lambda x: x[1])[0]
                            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º–µ–Ω–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
                            speaker_num = 0 if "0" in str(dominant_speaker) else 1
                            segment["speaker"] = f"SPEAKER_{speaker_num:02d}"
                        else:
                            segment["speaker"] = "SPEAKER_00"
                
                except Exception as e:
                    print(f"‚ö†Ô∏è  –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞: {str(e)[:60]}")
                    for segment in result["segments"]:
                        segment["speaker"] = "SPEAKER_00"
            else:
                for segment in result["segments"]:
                    segment["speaker"] = "SPEAKER_00"
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            full_text = " ".join([seg.get("text", "") for seg in result["segments"]])
            
            speakers_text = []
            current_speaker = None
            current_text = []
            current_start = 0
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–ø–ª–∏–∫–∏ –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
            for seg in result["segments"]:
                speaker = seg.get("speaker", "SPEAKER_00")
                text = seg.get("text", "").strip()
                
                if not text:
                    continue
                
                if speaker != current_speaker:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Ä–µ–ø–ª–∏–∫—É
                    if current_text:
                        speakers_text.append({
                            "speaker": current_speaker,
                            "text": " ".join(current_text),
                            "start": current_start,
                            "end": seg.get("start", 0)
                        })
                    # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Ä–µ–ø–ª–∏–∫—É
                    current_speaker = speaker
                    current_text = [text]
                    current_start = seg.get("start", 0)
                else:
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–µ–∫—É—â—É—é —Ä–µ–ø–ª–∏–∫—É
                    current_text.append(text)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–ø–ª–∏–∫—É
            if current_text:
                speakers_text.append({
                    "speaker": current_speaker,
                    "text": " ".join(current_text),
                    "start": current_start,
                    "end": result["segments"][-1].get("end", 0)
                })
            
            return {
                "transcript": full_text.strip(),
                "speakers": speakers_text,
                "duration": audio.shape[0] / 16000,
                "num_speakers": len(set([s['speaker'] for s in speakers_text])),
                "status": "success"
            }
        except Exception as e:
            return {
                "transcript": "",
                "speakers": [],
                "duration": 0,
                "num_speakers": 0,
                "status": "error",
                "error": str(e)
            }
    
    def cleanup(self):
        try:
            del self.model
            del self.align_model
            if self.diarize_model:
                del self.diarize_model
            gc.collect()
        except:
            pass
